{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<a id=\"Content\">HnM RecSys Notebook 9417</a>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-output": false,
    "tags": []
   },
   "source": [
    "## **<a id=\"Content\">Table of Contents</a>**\n",
    "* [**<span>1. Imports</span>**](#Imports)  \n",
    "* [**<span>2. Pre-Processing</span>**](#Pre-Processing)\n",
    "* [**<span>3. Exploratory Data Analysis</span>**](#Exploratory-Data-Analysis)  \n",
    "    * [**<span>3.1 Articles</span>**](#EDA::Articles)  \n",
    "    * [**<span>3.2 Customers</span>**](#EDA::Customers)\n",
    "    * [**<span>3.3 Transactions</span>**](#EDA::Transactions)\n",
    "* [**<span>4. Helper FunctionsDecorators</span>**](#Helper-Functions)\n",
    "* [**<span>5. Models</span>**](#Models) \n",
    "    * [**<span>5.1 Popularity</span>**](#Popularity-Model)   \n",
    "    * [**<span>5.2 ALS</span>**](#Alternating-Least-Squares)  \n",
    "    * [**<span>5.2 GBDT</span>**](#GBDT)  \n",
    "    * [**<span>5.3 SGD/similar</span>**](#SGD)  \n",
    "    * [**<span>5.4 NN</span>**](#NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id  product_code          prod_name  product_type_no   \n",
      "0   108775015        108775          Strap top              253  \\\n",
      "1   108775044        108775          Strap top              253   \n",
      "2   108775051        108775      Strap top (1)              253   \n",
      "3   110065001        110065  OP T-shirt (Idro)              306   \n",
      "4   110065002        110065  OP T-shirt (Idro)              306   \n",
      "\n",
      "  product_type_name  product_group_name  graphical_appearance_no   \n",
      "0          Vest top  Garment Upper body                  1010016  \\\n",
      "1          Vest top  Garment Upper body                  1010016   \n",
      "2          Vest top  Garment Upper body                  1010017   \n",
      "3               Bra           Underwear                  1010016   \n",
      "4               Bra           Underwear                  1010016   \n",
      "\n",
      "  graphical_appearance_name  colour_group_code colour_group_name  ...   \n",
      "0                     Solid                  9             Black  ...  \\\n",
      "1                     Solid                 10             White  ...   \n",
      "2                    Stripe                 11         Off White  ...   \n",
      "3                     Solid                  9             Black  ...   \n",
      "4                     Solid                 10             White  ...   \n",
      "\n",
      "   department_name index_code        index_name index_group_no   \n",
      "0     Jersey Basic          A        Ladieswear              1  \\\n",
      "1     Jersey Basic          A        Ladieswear              1   \n",
      "2     Jersey Basic          A        Ladieswear              1   \n",
      "3   Clean Lingerie          B  Lingeries/Tights              1   \n",
      "4   Clean Lingerie          B  Lingeries/Tights              1   \n",
      "\n",
      "   index_group_name section_no            section_name garment_group_no   \n",
      "0        Ladieswear         16  Womens Everyday Basics             1002  \\\n",
      "1        Ladieswear         16  Womens Everyday Basics             1002   \n",
      "2        Ladieswear         16  Womens Everyday Basics             1002   \n",
      "3        Ladieswear         61         Womens Lingerie             1017   \n",
      "4        Ladieswear         61         Womens Lingerie             1017   \n",
      "\n",
      "   garment_group_name                                        detail_desc  \n",
      "0        Jersey Basic            Jersey top with narrow shoulder straps.  \n",
      "1        Jersey Basic            Jersey top with narrow shoulder straps.  \n",
      "2        Jersey Basic            Jersey top with narrow shoulder straps.  \n",
      "3   Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
      "4   Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "--\n",
      "                                         customer_id     FN  Active   \n",
      "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...    NaN     NaN  \\\n",
      "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...    NaN     NaN   \n",
      "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    NaN     NaN   \n",
      "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...    NaN     NaN   \n",
      "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f... 1.0000  1.0000   \n",
      "\n",
      "  club_member_status fashion_news_frequency     age   \n",
      "0             ACTIVE                   NONE 49.0000  \\\n",
      "1             ACTIVE                   NONE 25.0000   \n",
      "2             ACTIVE                   NONE 24.0000   \n",
      "3             ACTIVE                   NONE 54.0000   \n",
      "4             ACTIVE              Regularly 52.0000   \n",
      "\n",
      "                                         postal_code  \n",
      "0  52043ee2162cf5aa7ee79974281641c6f11a68d276429a...  \n",
      "1  2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...  \n",
      "2  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...  \n",
      "3  5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...  \n",
      "4  25fa5ddee9aac01b35208d01736e57942317d756b32ddd...  \n",
      "--\n",
      "        t_dat                                        customer_id  article_id   \n",
      "0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001  \\\n",
      "1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023   \n",
      "2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004   \n",
      "3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687003   \n",
      "4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687004   \n",
      "\n",
      "   price  sales_channel_id  \n",
      "0 0.0508                 2  \n",
      "1 0.0305                 2  \n",
      "2 0.0152                 2  \n",
      "3 0.0169                 2  \n",
      "4 0.0169                 2  \n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "# import cudf # switch on P100 GPU for this to work in Kaggle\n",
    "# import cupy as cp\n",
    "\n",
    "# Importing data\n",
    "articles = pd.read_csv('articles.csv')\n",
    "print(articles.head())\n",
    "print(\"--\")\n",
    "customers = pd.read_csv('customers.csv')\n",
    "print(customers.head())\n",
    "print(\"--\")\n",
    "transactions = pd.read_csv(\"transactions_train.csv\")\n",
    "print(transactions.head())\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: \n",
      "customer_id                    0\n",
      "FN                        895050\n",
      "Active                    907576\n",
      "club_member_status          6062\n",
      "fashion_news_frequency     16011\n",
      "age                        15861\n",
      "postal_code                    0\n",
      "dtype: int64\n",
      "--\n",
      "\n",
      "FN Newsletter vals:  [nan  1.]\n",
      "Active communication vals:  [nan  1.]\n",
      "Club member status vals:  ['ACTIVE' nan 'PRE-CREATE' 'LEFT CLUB']\n",
      "Fashion News frequency vals:  ['NONE' 'Regularly' nan 'Monthly']\n",
      "--\n",
      "\n",
      "Customers' Missing values: \n",
      "customer_id               0\n",
      "FN                        0\n",
      "Active                    0\n",
      "club_member_status        0\n",
      "fashion_news_frequency    0\n",
      "age                       0\n",
      "postal_code               0\n",
      "dtype: int64\n",
      "--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- empty value stats -------------\n",
    "print(\"Missing values: \")\n",
    "print(customers.isnull().sum())\n",
    "print(\"--\\n\")\n",
    "\n",
    "print(\"FN Newsletter vals: \", customers['FN'].unique())\n",
    "print(\"Active communication vals: \",customers['Active'].unique())\n",
    "print(\"Club member status vals: \", customers['club_member_status'].unique())\n",
    "print(\"Fashion News frequency vals: \", customers['fashion_news_frequency'].unique())\n",
    "print(\"--\\n\")\n",
    "\n",
    "# ---- data cleaning -------------\n",
    "\n",
    "customers['FN'] = customers['FN'].fillna(0)\n",
    "customers['Active'] = customers['Active'].fillna(0)\n",
    "\n",
    "# replace club_member_status missing values with 'LEFT CLUB' --> no members with LEFT CLUB status in data\n",
    "customers['club_member_status'] = customers['club_member_status'].fillna('LEFT CLUB')\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].fillna('None')\n",
    "customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('NONE', 'None')\n",
    "customers['age'] = customers['age'].fillna(customers['age'].mean())\n",
    "customers['age'] = customers['age'].astype(int)\n",
    "articles['detail_desc'] = articles['detail_desc'].fillna('None')\n",
    "\n",
    "\n",
    "print(\"Customers' Missing values: \")\n",
    "print(customers.isnull().sum())\n",
    "print(\"--\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- memory optimizations -------------\n",
    "\n",
    "# reference: https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65\n",
    "\n",
    "# iterate through all the columns of a dataframe and reduce the int and float data types to the smallest possible size, ex. customer_id should not be reduced from int64 to a samller value as it would have collisions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\"Iterate over all the columns of a DataFrame and modify the data type\n",
    "    to reduce memory usage, handling ordered Categoricals\"\"\"\n",
    "    \n",
    "    # check the memory usage of the DataFrame\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type == 'category':\n",
    "            if df[col].cat.ordered:\n",
    "                # Convert ordered Categorical to an integer\n",
    "                df[col] = df[col].cat.codes.astype('int16')\n",
    "            else:\n",
    "                # Convert unordered Categorical to a string\n",
    "                df[col] = df[col].astype('str')\n",
    "        \n",
    "        elif col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    \n",
    "    # check the memory usage after optimization\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "\n",
    "    # calculate the percentage of the memory usage reduction\n",
    "    mem_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(\"Memory usage decreased by {:.1f}%\".format(mem_reduction))\n",
    "    \n",
    "    return df\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles Info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105542 entries, 0 to 105541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   article_id                    105542 non-null  int64 \n",
      " 1   product_code                  105542 non-null  int64 \n",
      " 2   prod_name                     105542 non-null  object\n",
      " 3   product_type_no               105542 non-null  int64 \n",
      " 4   product_type_name             105542 non-null  object\n",
      " 5   product_group_name            105542 non-null  object\n",
      " 6   graphical_appearance_no       105542 non-null  int64 \n",
      " 7   graphical_appearance_name     105542 non-null  object\n",
      " 8   colour_group_code             105542 non-null  int64 \n",
      " 9   colour_group_name             105542 non-null  object\n",
      " 10  perceived_colour_value_id     105542 non-null  int64 \n",
      " 11  perceived_colour_value_name   105542 non-null  object\n",
      " 12  perceived_colour_master_id    105542 non-null  int64 \n",
      " 13  perceived_colour_master_name  105542 non-null  object\n",
      " 14  department_no                 105542 non-null  int64 \n",
      " 15  department_name               105542 non-null  object\n",
      " 16  index_code                    105542 non-null  object\n",
      " 17  index_name                    105542 non-null  object\n",
      " 18  index_group_no                105542 non-null  int64 \n",
      " 19  index_group_name              105542 non-null  object\n",
      " 20  section_no                    105542 non-null  int64 \n",
      " 21  section_name                  105542 non-null  object\n",
      " 22  garment_group_no              105542 non-null  int64 \n",
      " 23  garment_group_name            105542 non-null  object\n",
      " 24  detail_desc                   105542 non-null  object\n",
      "dtypes: int64(11), object(14)\n",
      "memory usage: 20.1+ MB\n",
      "None\n",
      "Customer Info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371980 entries, 0 to 1371979\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   customer_id             1371980 non-null  object \n",
      " 1   FN                      1371980 non-null  float64\n",
      " 2   Active                  1371980 non-null  float64\n",
      " 3   club_member_status      1371980 non-null  object \n",
      " 4   fashion_news_frequency  1371980 non-null  object \n",
      " 5   age                     1371980 non-null  int32  \n",
      " 6   postal_code             1371980 non-null  object \n",
      "dtypes: float64(2), int32(1), object(4)\n",
      "memory usage: 68.0+ MB\n",
      "None\n",
      "Transactions Info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31788324 entries, 0 to 31788323\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   t_dat             object \n",
      " 1   customer_id       object \n",
      " 2   article_id        int64  \n",
      " 3   price             float64\n",
      " 4   sales_channel_id  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.2+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Articles Info: \")\n",
    "print(articles.info())\n",
    "print(\"Customer Info: \")\n",
    "print(customers.info())\n",
    "print(\"Transactions Info: \")\n",
    "print(transactions.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 20.13 MB\n",
      "Memory usage after optimization is: 13.59 MB\n",
      "Memory usage decreased by 32.5%\n",
      "Memory usage of dataframe is 68.04 MB\n",
      "Memory usage after optimization is: 48.41 MB\n",
      "Memory usage decreased by 28.8%\n",
      "Memory usage of dataframe is 1212.63 MB\n",
      "Memory usage after optimization is: 697.26 MB\n",
      "Memory usage decreased by 42.5%\n",
      "Articles Info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105542 entries, 0 to 105541\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   article_id                    105542 non-null  int32 \n",
      " 1   product_code                  105542 non-null  int32 \n",
      " 2   prod_name                     105542 non-null  object\n",
      " 3   product_type_no               105542 non-null  int16 \n",
      " 4   product_type_name             105542 non-null  object\n",
      " 5   product_group_name            105542 non-null  object\n",
      " 6   graphical_appearance_no       105542 non-null  int32 \n",
      " 7   graphical_appearance_name     105542 non-null  object\n",
      " 8   colour_group_code             105542 non-null  int8  \n",
      " 9   colour_group_name             105542 non-null  object\n",
      " 10  perceived_colour_value_id     105542 non-null  int8  \n",
      " 11  perceived_colour_value_name   105542 non-null  object\n",
      " 12  perceived_colour_master_id    105542 non-null  int8  \n",
      " 13  perceived_colour_master_name  105542 non-null  object\n",
      " 14  department_no                 105542 non-null  int16 \n",
      " 15  department_name               105542 non-null  object\n",
      " 16  index_code                    105542 non-null  object\n",
      " 17  index_name                    105542 non-null  object\n",
      " 18  index_group_no                105542 non-null  int8  \n",
      " 19  index_group_name              105542 non-null  object\n",
      " 20  section_no                    105542 non-null  int8  \n",
      " 21  section_name                  105542 non-null  object\n",
      " 22  garment_group_no              105542 non-null  int16 \n",
      " 23  garment_group_name            105542 non-null  object\n",
      " 24  detail_desc                   105542 non-null  object\n",
      "dtypes: int16(3), int32(3), int8(5), object(14)\n",
      "memory usage: 13.6+ MB\n",
      "None\n",
      "Customer Info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1371980 entries, 0 to 1371979\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count    Dtype  \n",
      "---  ------                  --------------    -----  \n",
      " 0   customer_id             1371980 non-null  int64  \n",
      " 1   FN                      1371980 non-null  float16\n",
      " 2   Active                  1371980 non-null  float16\n",
      " 3   club_member_status      1371980 non-null  object \n",
      " 4   fashion_news_frequency  1371980 non-null  object \n",
      " 5   age                     1371980 non-null  int8   \n",
      " 6   postal_code             1371980 non-null  object \n",
      "dtypes: float16(2), int64(1), int8(1), object(3)\n",
      "memory usage: 48.4+ MB\n",
      "None\n",
      "Transactions Info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31788324 entries, 0 to 31788323\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   t_dat             object \n",
      " 1   customer_id       int64  \n",
      " 2   article_id        int32  \n",
      " 3   price             float16\n",
      " 4   sales_channel_id  int8   \n",
      "dtypes: float16(1), int32(1), int64(1), int8(1), object(1)\n",
      "memory usage: 697.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ---- memory optimizations -------------\n",
    "\n",
    "# uses 8 bytes instead of given 64 byte string, reduces mem by 8x, \n",
    "# !!!! have to convert back before merging w/ sample_submissions.csv\n",
    "# convert transactions['customer_id'] to 8 bytes int\n",
    "# transactions['customer_id'] = transactions['customer_id'].astype('int64')\n",
    "transactions['customer_id'] = transactions['customer_id'].apply(lambda x: int(x[-16:], 16)).astype('int64')\n",
    "customers['customer_id'] = customers['customer_id'].apply(lambda x: int(x[-16:], 16)).astype('int64')\n",
    "\n",
    "articles = reduce_mem_usage(articles)\n",
    "customers = reduce_mem_usage(customers)\n",
    "transactions = reduce_mem_usage(transactions)\n",
    "\n",
    "# articles['article_id'] = articles['article_id'].astype('int32')\n",
    "# transactions['article_id'] = transactions['article_id'].astype('int32') \n",
    "# # !!!! ADD LEADING ZERO BACK BEFORE SUBMISSION OF PREDICTIONS TO KAGGLE: \n",
    "# # Ex.: transactions['article_id'] = '0' + transactions.article_id.astype('str')\n",
    "\n",
    "print(\"Articles Info: \")\n",
    "print(articles.info())\n",
    "print(\"Customer Info: \")\n",
    "print(customers.info())\n",
    "print(\"Transactions Info: \")\n",
    "print(transactions.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper-Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://towardsdatascience.com/python-decorators-for-data-science-6913f717669a\n",
    "\n",
    "# memoization decorator\n",
    "def memoize(func):\n",
    "    cache = {}\n",
    "    def wrapper(*args):\n",
    "        if args in cache:\n",
    "            return cache[args]\n",
    "        else:\n",
    "            result = func(*args)\n",
    "            cache[args] = result\n",
    "            return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-based splitting strategy\n",
    "\n",
    "def split_train_val_data(transactions, days=7):\n",
    "    \"\"\"\n",
    "    Splits the transaction training data into a training set and a validation set of 7 days to prevent data leakage.\n",
    "    \"\"\"\n",
    "    \n",
    "    transactions['t_dat'] = pd.to_datetime(transactions['t_dat'])\n",
    "    transactions = transactions.sort_values(by=['t_dat'])\n",
    "    latest_transaction_date = transactions['t_dat'].max()\n",
    "    \n",
    "    training_set = transactions[transactions['t_dat'] < latest_transaction_date - pd.Timedelta(days=days)]\n",
    "    validation_set = transactions[transactions['t_dat'] >= latest_transaction_date - pd.Timedelta(days=days)]\n",
    "    \n",
    "    print(\"Training set size:\", len(training_set))\n",
    "    print(\"Validation set size:\", len(validation_set))\n",
    "    print(\"Last date in training set:\", training_set['t_dat'].max())\n",
    "    print(\"Last date in validation set:\", validation_set['t_dat'].max())\n",
    "    \n",
    "    return training_set, validation_set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating-Least-Squares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS simply factorizes the the user-item interaction matrix, and creates two latent factor matrices: one for users and one for items. <br>\n",
    "Used Bayesian Optimization for hyperparameter tuning to find the best hyperparameters. <br>\n",
    "This model can deal well with sparse data, but makes low quality predictions based on the implicit feedback. <br>\n",
    "\n",
    "The sparsity of the data, due to the fact that most H&M customers only buy a few items, is a problem for the ALS model. The more sparse the data, the lower the recommendation quality.<br>\n",
    "\n",
    "The final tuned model is also used in LightGBM to factorize the user-item matrix - for cosine similairty features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmdoh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(transactions_df, customers_df, articles_df, customers_col='customer_id', articles_col='article_id'):\n",
    "    \"\"\"\n",
    "    Preprocesses customer and article IDs for use in a sparse matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - transactions_df: the input transaction DataFrame with two additional columns, 'user_index' and 'item_index',\n",
    "                       that map customer and article IDs to their corresponding indices in a sparse matrix\n",
    "    - customer_id_indices_map: a dictionary that maps customer IDs to their corresponding indices\n",
    "    - article_id_indices_map: a dictionary that maps article IDs to their corresponding indices\n",
    "    \"\"\"\n",
    "    # Create a list of unique customer IDs and product IDs\n",
    "    all_customers = customers_df[customers_col].unique().tolist()\n",
    "    all_articles = articles_df[articles_col].unique().tolist()\n",
    "\n",
    "    # Create dicts mapping IDs to their corresponding indices\n",
    "    customer_id_indices_map = {customer_id: i for i, customer_id in enumerate(all_customers)}\n",
    "    article_id_indices_map = {article_id: i for i, article_id in enumerate(all_articles)}\n",
    "\n",
    "    # Map customer and article IDs to their resp. indices in the transaction DataFrame\n",
    "    transactions_df['user_index'] = transactions_df[customers_col].map(customer_id_indices_map)\n",
    "    transactions_df['item_index'] = transactions_df[articles_col].map(article_id_indices_map)\n",
    "\n",
    "    return transactions_df, all_customers, all_articles, customer_id_indices_map, article_id_indices_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of customers:  1371980\n",
      "Total num of articles:  105542\n",
      "Customer ID mapping:  [(6883939031699146327, 0), (-7200416642310594310, 1), (-6846340800584936, 2), (-94071612138601410, 3), (-283965518499174310, 4)]\n",
      "Article ID mapping:  [(108775015, 0), (108775044, 1), (108775051, 2), (110065001, 3), (110065002, 4)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>-6846340800584936</td>\n",
       "      <td>663713001</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>40179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>-6846340800584936</td>\n",
       "      <td>541518023</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>-8334631767138808638</td>\n",
       "      <td>505221004</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>-8334631767138808638</td>\n",
       "      <td>685687003</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>46304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>-8334631767138808638</td>\n",
       "      <td>685687004</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>46305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_dat          customer_id  article_id  price  sales_channel_id   \n",
       "0 2018-09-20    -6846340800584936   663713001 0.0508                 2  \\\n",
       "1 2018-09-20    -6846340800584936   541518023 0.0305                 2   \n",
       "2 2018-09-20 -8334631767138808638   505221004 0.0152                 2   \n",
       "3 2018-09-20 -8334631767138808638   685687003 0.0169                 2   \n",
       "4 2018-09-20 -8334631767138808638   685687004 0.0169                 2   \n",
       "\n",
       "   user_index  item_index  \n",
       "0           2       40179  \n",
       "1           2       10520  \n",
       "2           7        6387  \n",
       "3           7       46304  \n",
       "4           7       46305  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions, all_customers, all_articles, customer_id_indices_map, article_id_indices_map = preprocess_data(transactions, customers, articles)\n",
    "\n",
    "print(\"Total num of customers: \", len(all_customers))\n",
    "print(\"Total num of articles: \", len(all_articles))\n",
    "print(\"Customer ID mapping: \", list(customer_id_indices_map.items())[:5])\n",
    "print(\"Article ID mapping: \", list(article_id_indices_map.items())[:5])\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 31521960\n",
      "Validation set size: 266364\n",
      "Last date in training set: 2020-09-14 00:00:00\n",
      "Last date in validation set: 2020-09-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "training_set, validation_set = split_train_val_data(transactions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ALS strategy.</b><br> binary `implicit feedback`: based on whether a product was purchased or not (purchase quantity is not taken into consideration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse matrix of all user-item (a.k.a customer_id-article_id) interactions\n",
    "# Supply training set, val set or entire transactions df\n",
    "\n",
    "def create_user_item_matrix(transactions_df):\n",
    "    # all customers and articles in their resp. rows of transaction data indicate that an article was purchased, thus:\n",
    "    interaction = np.ones(transactions_df.shape[0]) \n",
    "    user_rows = transactions_df['user_index'].values\n",
    "    item_cols = transactions_df['item_index'].values\n",
    "\n",
    "    user_item_matrix = sparse.csr_matrix((interaction, (user_rows, item_cols)), shape=(len(all_customers), len(all_articles)))\n",
    "    \n",
    "    return user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 99)\t1.0\n",
      "  (0, 16003)\t2.0\n",
      "  (0, 16023)\t1.0\n",
      "  (0, 23996)\t1.0\n",
      "  (0, 29516)\t1.0\n",
      "  (0, 30327)\t1.0\n",
      "  (0, 38172)\t1.0\n",
      "  (0, 49478)\t1.0\n",
      "  (0, 50724)\t1.0\n",
      "  (0, 65667)\t1.0\n",
      "  (0, 76503)\t1.0\n",
      "  (0, 76590)\t1.0\n",
      "  (0, 78719)\t1.0\n",
      "  (0, 79278)\t2.0\n",
      "  (0, 83622)\t1.0\n",
      "  (0, 90060)\t1.0\n",
      "  (0, 93744)\t1.0\n",
      "  (0, 99926)\t1.0\n",
      "  (0, 100484)\t1.0\n"
     ]
    }
   ],
   "source": [
    "user_item_training_matrix = create_user_item_matrix(training_set)\n",
    "user_item_validation_matrix = create_user_item_matrix(validation_set)\n",
    "\n",
    "user_item_training_matrix\n",
    "\n",
    "# print the first row value in the matrix\n",
    "print(user_item_training_matrix[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above CSR matrix output row: `(x, yyyy)\tz`: <br>\n",
    "'x' (row index) corresponds to the index-encoded `customer_id` <br>\n",
    "'y' (column index) corresponds to the index-encoded `article_id` <br>\n",
    "'z' corresponds to total number of purchases of 'yyyy' by 'x'<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1,371,980 customers and 105542 articles in transaction data (as seen previously). <br>\n",
    "There are 27,079,047 interactions in the matrix. There are a total of 27,306,439 unique interactions (if we used the entire transaction dataset to create the matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings matrix sparsity:  99.98129919611401\n"
     ]
    }
   ],
   "source": [
    "# Calculating Sparsity of sparse_ratings_matrix\n",
    "\n",
    "sparse_matrix_size = user_item_training_matrix.shape[0]*user_item_training_matrix.shape[1] \n",
    "num_purchases = len(user_item_training_matrix.nonzero()[0]) \n",
    "sparsity = 100*(1 - (num_purchases/sparse_matrix_size))\n",
    "print(\"ratings matrix sparsity: \", sparsity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>note: the current ratings matrix has 99.98% sparsity, and could thus affect the quality of recommendations.</b> <br>\n",
    "~31,000,000 (all) transactions sparsity: 99.98% <br>\n",
    "1,000,000 transactions sparsity: 99.997% <br>\n",
    "500,000 transactions sparsity: 99.997% <br>\n",
    "100,000 transactions sparsity: 99.996% <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training:</b> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import implicit\n",
    "\n",
    "# default values taken from : http://yifanhu.net/PUB/cf.pdf\n",
    "\n",
    "def train_als_model(user_item_matrix, factors=50, iterations=20, regularization=0.1, alpha = 50, random_state=69, use_gpu=False):\n",
    "    \"\"\"\n",
    "    Trains an ALS model using implicit library and returns the trained model.\n",
    "    \n",
    "    Args:\n",
    "    - user_item_matrix: a sparse user-item matrix in CSR format\n",
    "    - factors: the number of latent factors to use (default=500)\n",
    "    - alpha: multiply alpha to training to scale the confidence of the user-item interactions (default=1)\n",
    "  \n",
    "    Returns:\n",
    "    - als_model: the trained ALS model\n",
    "    \"\"\"\n",
    "    \n",
    "    # set logging level to DEBUG\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    \n",
    "    \n",
    "    als_model = implicit.als.AlternatingLeastSquares(factors=factors, iterations=iterations, regularization=regularization, \n",
    "                                                     random_state=random_state, use_gpu=use_gpu)\n",
    "    als_model.fit(user_item_matrix*alpha, show_progress=True)\n",
    "    \n",
    "    return als_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:implicit:Calculated transpose in 0.311s\n",
      "DEBUG:implicit:Initialized factors in 0.7812304496765137\n",
      "DEBUG:implicit:Running 20 ALS iterations\n",
      "100%|██████████| 20/20 [08:41<00:00, 26.06s/it]\n"
     ]
    }
   ],
   "source": [
    "als_model = train_als_model(user_item_training_matrix, alpha=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 50)\n",
      "---\n",
      "(105542, 50)\n"
     ]
    }
   ],
   "source": [
    "# Check the array of user and item latent factors in the training set\n",
    "print(als_model.user_factors.shape)\n",
    "print(\"---\")\n",
    "print(als_model.item_factors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation:</b> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75481/75481 [00:20<00:00, 3716.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Using KMAP@12 to validate the model\n",
    "\n",
    "from implicit.evaluation import mean_average_precision_at_k as map_at_k\n",
    "\n",
    "map_12 = map_at_k(als_model, user_item_training_matrix, user_item_validation_matrix, K=12, show_progress=True, num_threads=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0037245391463783645"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "# references: https://github.com/fmfn/BayesianOptimization/blob/master/examples/basic-tour.ipynb\n",
    "#             https://towardsdatascience.com/bayesian-optimization-concept-explained-in-layman-terms\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "from implicit.evaluation import mean_average_precision_at_k as map_at_k\n",
    "\n",
    "\n",
    "# map_at_k is the objective function to be maximized\n",
    "def map_at_k_als(factors, iterations, regularization, alpha):\n",
    "    global user_item_training_matrix, user_item_validation_matrix\n",
    "    als_model = implicit.als.AlternatingLeastSquares(factors=int(factors), iterations=int(iterations), \n",
    "                                                     regularization=regularization, random_state=69, use_gpu=False)\n",
    "    als_model.fit(user_item_training_matrix*alpha, show_progress=True)\n",
    "    map_12 = map_at_k(als_model, user_item_training_matrix, user_item_validation_matrix, K=12, show_progress=False, num_threads=1)\n",
    "    return map_12\n",
    "\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'factors': (10, 500), 'iterations': (1, 100), 'regularization': (0.01, 0.5), 'alpha': (10, 100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=map_at_k_als,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "logger = JSONLogger(path=\"./als/als_strat1_logs.json\")\n",
    "optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)\n",
    "\n",
    "user_item_training_matrix, user_item_validation_matrix\n",
    "optimizer.maximize(\n",
    "    init_points=5, # number of bayesian optimization steps to perform\n",
    "    n_iter=10, # how many steps of random exploration to perform -- diversifies exploration space\n",
    "    # acq='ucb', # acquisition function type\n",
    "    # kappa=2.576, # balance between exploration and exploitation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.004267258343715801,\n",
       " 'params': {'alpha': 20.51678125995256,\n",
       "  'factors': 151.9606520546814,\n",
       "  'iterations': 99.51984263986631,\n",
       "  'regularization': 0.4375570316637724}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bayes_opt.util import load_logs\n",
    "\n",
    "loaded_optimizer = BayesianOptimization(\n",
    "    f=map_at_k_als,\n",
    "    pbounds=pbounds,\n",
    "    verbose=1,\n",
    "    random_state=2,\n",
    ")\n",
    "\n",
    "\n",
    "load_logs(loaded_optimizer, logs=[\"./als/als_strat1_logs.json\"])\n",
    "loaded_optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:implicit:Calculated transpose in 0.379s\n",
      "DEBUG:implicit:Initialized factors in 2.5063974857330322\n",
      "DEBUG:implicit:Running 99 ALS iterations\n",
      "100%|██████████| 99/99 [1:06:43<00:00, 40.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 151)\n",
      "---\n",
      "(105542, 151)\n"
     ]
    }
   ],
   "source": [
    "# Final ALS model with best hyperparameters and all training data\n",
    "\n",
    "best_hyperparams = loaded_optimizer.max['params']\n",
    "\n",
    "user_item_train_matrix = create_user_item_matrix(transactions)\n",
    "als_model = train_als_model(user_item_train_matrix, int(best_hyperparams['factors']), int(best_hyperparams['iterations']), int(best_hyperparams['regularization']), int(best_hyperparams['alpha']))\n",
    "\n",
    "# Check the array of user and item latent factors in the training set\n",
    "print(als_model.user_factors.shape)\n",
    "print(\"---\")\n",
    "print(als_model.item_factors.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> As we can see, the ALS model performs quite poorly on the test set, with a max MAP score od 0.0043 post-Bayesian Optimizaation. </b> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the als model as a pickle file\n",
    "import pickle\n",
    "\n",
    "with open('als/als_model_strat1.pkl', 'wb') as f:\n",
    "    pickle.dump(als_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission function that generates top 12 recommendations for each customer_id and appends to submission.csv\n",
    "# if the customer_id is not in the training set, then the top 12 articles are recommended\n",
    "# ensure that customer_id and article_id are strings\n",
    "\n",
    "\n",
    "# reverse dictionary that maps index to article_id\n",
    "index_article_id_map = {v: k for k, v in article_id_indices_map.items()}\n",
    "index_customer_id_map = {v: k for k, v in customer_id_indices_map.items()}\n",
    "\n",
    "# given an article_index, return the original article_id\n",
    "def get_og_article_id(article_index):\n",
    "    return '0' + str(index_article_id_map.get(article_index, None))\n",
    "\n",
    "\n",
    "def submission_als(als_model):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "    - als_model: the trained ALS model\n",
    " \n",
    "    Returns:\n",
    "    - submission.csv: a csv file with the top 12 recommendations for each customer_id\n",
    "    \"\"\"\n",
    "    no_interaction_count = 0\n",
    "    samp_sub = pd.read_csv('sample_submission.csv')\n",
    "    sub_customer_ids = samp_sub['customer_id'].apply(lambda x: int(x[-16:], 16)).astype('int64') \n",
    "\n",
    "    # map sample_sub customer_id to sub_customer_ids\n",
    "    customer_id_sub_map = dict(zip(sub_customer_ids, samp_sub['customer_id']))\n",
    "\n",
    "    # iterate thru all customer_ids in all_customers\n",
    "    # generate top 12 recommendations for each customer_id using the trained als model\n",
    "\n",
    "    predictions = []\n",
    "    for customer_index in range(0, len(all_customers)):\n",
    "        if customer_index not in user_item_train_matrix.indptr:\n",
    "            recommended_articles = latest_top_12_products\n",
    "            no_interaction_count += 1\n",
    "        else:\n",
    "            # filter_already_liked_items=False ==> recommend items that the user has already interacted with as well\n",
    "            recco_articles, scores = als_model.recommend(customer_index, user_item_train_matrix, N=12, filter_already_liked_items=False)\n",
    "            recommended_articles = [article_id for article_id in recco_articles]\n",
    "            \n",
    "        article_ids = [get_og_article_id(article_id) for article_id in recommended_articles]\n",
    "        # append the top 12 recommendations for each customer_id to predictions\n",
    "        predictions.append((customer_id_sub_map[index_customer_id_map[customer_index]], ' '.join(article_ids)))\n",
    "\n",
    "    submission_df = pd.DataFrame(predictions, columns=['customer_id', 'prediction'])\n",
    "    submission_df.to_csv('als/als_strat_submission.csv', index=False)\n",
    "    display(submission_df.head())\n",
    "    print(submission_df.shape)\n",
    "\n",
    "    return submission_df, no_interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0568601006 0568597006 0568601007 0795440001 05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id   \n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  \\\n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0568601006 0568597006 0568601007 0795440001 05...  \n",
       "1  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "2  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "3  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "4  0306847011 0288825017 0288825012 0283236034 02...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 2)\n"
     ]
    }
   ],
   "source": [
    "predictions, no_interaction_count = submission_als(als_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.03600635577779"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_interaction_count/len(all_customers) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 95% of customers dont have any interaction rows in the sparse matrix, and thus the model is unable to make recommendations for these customers. <br> This is a cold start problem, and we will use the popularity model to recommend the top 12 items to these customers instead. <br>\n",
    "\n",
    "Intuitively, we can see that ALS is not the best model for this dataset, since the ratings matrix is very sparse, and thus the model is unable to make recommendations for most customers. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission function that just pust latest top 12 products for each customer_id and appends to submission.csv\n",
    "\n",
    "def submission_pop(popularity_model):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "    - als_model: the trained ALS model\n",
    " \n",
    "    Returns:\n",
    "    - submission.csv: a csv file with the top 12 recommendations for each customer_id\n",
    "    \"\"\"\n",
    "    samp_sub = pd.read_csv('sample_submission.csv')\n",
    "    sub_customer_ids = samp_sub['customer_id'].apply(lambda x: int(x[-16:], 16)).astype('int64') \n",
    "\n",
    "    # map sample_sub customer_id to sub_customer_ids\n",
    "    customer_id_sub_map = dict(zip(sub_customer_ids, samp_sub['customer_id']))\n",
    "\n",
    "    # iterate thru all customer_ids in all_customers\n",
    "    # generate top 12 recommendations for each customer_id using the trained als model\n",
    "\n",
    "    predictions = []\n",
    "    for customer_index in range(0, len(all_customers)):\n",
    "        recommended_articles = popularity_model\n",
    "        article_ids = [get_og_article_id(article_id) for article_id in recommended_articles]\n",
    "        # append the top 12 recommendations for each customer_id to predictions\n",
    "        predictions.append((customer_id_sub_map[index_customer_id_map[customer_index]], ' '.join(article_ids)))\n",
    "\n",
    "    submission_df = pd.DataFrame(predictions, columns=['customer_id', 'prediction'])\n",
    "    submission_df.to_csv('pop/popularity_strat_submission.csv', index=False)\n",
    "    display(submission_df.head())\n",
    "    print(submission_df.shape)\n",
    "\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0306847011 0288825017 0288825012 0283236034 02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id   \n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  \\\n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "1  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "2  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "3  0306847011 0288825017 0288825012 0283236034 02...  \n",
       "4  0306847011 0288825017 0288825012 0283236034 02...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 2)\n"
     ]
    }
   ],
   "source": [
    "popularity_predictions = submission_pop(latest_top_12_products)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
