{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<a id=\"Content\">HnM RecSys Notebook 9417</a>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-output": false,
    "tags": []
   },
   "source": [
    "## **<a id=\"Content\">Table of Contents</a>**\n",
    "* [**<span>1. Imports</span>**](#Imports)  \n",
    "* [**<span>2. Helper Functions/Decorators</span>**](#Helper-Functions)\n",
    "* [**<span>5. LightGBM Model</span>**](#LightGBM-Model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM imports\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open user_item_matrix_200\n",
    "with open('user_item_matrix_200.pkl', 'rb') as f:\n",
    "    user_item_matrix = pickle.load(f)\n",
    "\n",
    "# open customer and articels incides map\n",
    "with open('lightgbm/customer_id_indices_map.pkl', 'rb') as f:\n",
    "    customer_id_indices_map = pickle.load(f)\n",
    "\n",
    "with open('lightgbm/article_id_indices_map.pkl', 'rb') as f:\n",
    "    article_id_indices_map = pickle.load(f)\n",
    "\n",
    "# load df from pickle file for time-based split\n",
    "with open('lightgbm/df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# load final_df from pickle file for clean processing\n",
    "with open('lightgbm/final_df_with_binary_targets.pkl', 'rb') as f:\n",
    "    final_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_1</th>\n",
       "      <th>sales_channel_2</th>\n",
       "      <th>quantity</th>\n",
       "      <th>article_engagement_ratio</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>...</th>\n",
       "      <th>garment_group_no_1019.0</th>\n",
       "      <th>garment_group_no_1020.0</th>\n",
       "      <th>garment_group_no_1021.0</th>\n",
       "      <th>garment_group_no_1023.0</th>\n",
       "      <th>garment_group_no_1025.0</th>\n",
       "      <th>index_group_no_1.0</th>\n",
       "      <th>index_group_no_2.0</th>\n",
       "      <th>index_group_no_3.0</th>\n",
       "      <th>index_group_no_4.0</th>\n",
       "      <th>index_group_no_26.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042358</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>11563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050842</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>9899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>14438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016937</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>10307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016937</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>10</td>\n",
       "      <td>13608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  sales_channel_1  sales_channel_2  quantity   \n",
       "0  0.042358            False             True       1.0  \\\n",
       "1  0.050842            False             True       1.0   \n",
       "2  0.067810            False             True       1.0   \n",
       "3  0.016937            False             True       1.0   \n",
       "4  0.016937            False             True       1.0   \n",
       "\n",
       "   article_engagement_ratio  user_index  item_index   FN  Active   \n",
       "0                  1.000000           5       11563  1.0     1.0  \\\n",
       "1                  1.000000           5        9899  1.0     1.0   \n",
       "2                  1.000000           5       14438  1.0     1.0   \n",
       "3                  0.500000          10       10307  0.0     0.0   \n",
       "4                  0.166667          10       13608  0.0     0.0   \n",
       "\n",
       "   club_member_status  ...  garment_group_no_1019.0  garment_group_no_1020.0   \n",
       "0                 2.0  ...                    False                    False  \\\n",
       "1                 2.0  ...                    False                    False   \n",
       "2                 2.0  ...                    False                    False   \n",
       "3                 2.0  ...                    False                    False   \n",
       "4                 2.0  ...                    False                    False   \n",
       "\n",
       "   garment_group_no_1021.0  garment_group_no_1023.0  garment_group_no_1025.0   \n",
       "0                    False                    False                    False  \\\n",
       "1                    False                    False                    False   \n",
       "2                    False                    False                    False   \n",
       "3                    False                    False                    False   \n",
       "4                    False                     True                    False   \n",
       "\n",
       "   index_group_no_1.0  index_group_no_2.0  index_group_no_3.0   \n",
       "0                True               False               False  \\\n",
       "1                True               False               False   \n",
       "2                True               False               False   \n",
       "3               False                True               False   \n",
       "4                True               False               False   \n",
       "\n",
       "   index_group_no_4.0  index_group_no_26.0  \n",
       "0               False                False  \n",
       "1               False                False  \n",
       "2               False                False  \n",
       "3               False                False  \n",
       "4               False                False  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952211, 56)\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# only get top 50 customers by number of total pruchase quantity from final_df\n",
    "\n",
    "# Compute the total quantity for each user_index\n",
    "user_quantity = final_df.groupby('user_index')['quantity'].sum()\n",
    "\n",
    "# Get the top 50 user_indices by total quantity\n",
    "top_50_users = user_quantity.nlargest(50).index\n",
    "\n",
    "# Filter the final_df to include only the data for the top 50 users\n",
    "final_df_top_50 = final_df[final_df['user_index'].isin(top_50_users)].copy()\n",
    "# print the shape of final_df_top_50\n",
    "print(final_df_top_50.shape)\n",
    "\n",
    "print(final_df_top_50['user_index'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_train_test_split(final_df, test_size=0.2):\n",
    "\n",
    "    # Convert days, months, and years columns to datetime object\n",
    "    final_df['date'] = pd.to_datetime(final_df[['day', 'month', 'year']])\n",
    "\n",
    "    # Sort dataframe by date in ascending order\n",
    "    final_df = final_df.sort_values(by='date')\n",
    "\n",
    "    # Calculate cutoff index\n",
    "    cutoff_index = int(len(final_df) * (1-test_size))\n",
    "\n",
    "    # Create train and test dataframes\n",
    "    train_df = final_df[:cutoff_index]\n",
    "    test_df = final_df[cutoff_index:]\n",
    "\n",
    "    # Drop date column from train and test dataframes\n",
    "    train_df = train_df.drop('date', axis=1)\n",
    "    test_df = test_df.drop('date', axis=1)\n",
    "\n",
    "    # split train_df into X_train and y_train\n",
    "    X_train = train_df.drop('target', axis=1)\n",
    "    y_train = train_df['target']\n",
    "\n",
    "    # split test_df into X_test and y_test\n",
    "    X_test = test_df.drop('target', axis=1)\n",
    "    y_test = test_df['target']\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to insert random dates for each user in the df where there is no purchase (target = 0)\n",
    "# random dates are between user's first purchase date and last purchase date\n",
    "# if user has only one purchase, then the random date is the same as the purchase date\n",
    "# # if the user has no purchase, random date range is between df min and max dates\n",
    "\n",
    "def insert_random_dates(df):\n",
    "    # Group the DataFrame by user ID\n",
    "    grouped = final_df.groupby('user_index')\n",
    "\n",
    "    default_min_date = df['date'].min()\n",
    "    default_max_date = df['date'].max()\n",
    "    \n",
    "    print(\"df min date: \", default_min_date)\n",
    "    print(\"df max date: \", default_max_date)\n",
    "    \n",
    "    for user_id, group_df in grouped:\n",
    "    \n",
    "\n",
    "        # Find the missing dates for this user\n",
    "        missing_dates = group_df.loc[group_df['target'] == 0, 'date']\n",
    "\n",
    "        # If there are no missing dates, continue to the next user\n",
    "        if len(missing_dates) == 0:\n",
    "            continue\n",
    "\n",
    "        # Find the minimum and maximum purchase dates for this user\n",
    "        min_date = group_df['date'].min()\n",
    "        max_date = group_df['date'].max()\n",
    "    \n",
    "        # If the user has no purchase dates, use the default minimum and maximum dates\n",
    "        if pd.isna(min_date):\n",
    "            min_date = default_min_date\n",
    "        if pd.isna(max_date):\n",
    "            max_date = default_max_date\n",
    "\n",
    "        # Generate a list of random dates between the minimum and maximum purchase dates\n",
    "        random_dates = pd.date_range(start=min_date, end=max_date, freq='D').strftime('%Y-%m-%d')\n",
    "        # Only sample from random_dates if it has enough values\n",
    "        if len(random_dates) >= len(missing_dates):\n",
    "            random_dates = np.random.choice(random_dates, size=len(missing_dates), replace=False)\n",
    "        else:\n",
    "            random_dates = np.random.choice(pd.date_range(start=min_date, end=max_date, freq='D'), size=len(missing_dates), replace=True)\n",
    "\n",
    "        # Replace the missing dates with the random dates\n",
    "        group_df.loc[group_df['target'] == 0, 'date'] = random_dates\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df min date:  2018-09-20 00:00:00\n",
      "df max date:  2020-09-22 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7676429"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['date'] = pd.to_datetime(final_df[['day', 'month', 'year']])\n",
    "\n",
    "final_df = insert_random_dates(final_df)\n",
    "final_df['date'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7676429"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()\n",
    "\n",
    "# check how many null values in date column\n",
    "final_df['date'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1393.06 MB\n",
      "Memory usage after optimization is: 726.30 MB\n",
      "Memory usage decreased by 47.9%\n",
      "Memory usage of dataframe is 348.27 MB\n",
      "Memory usage after optimization is: 401.84 MB\n",
      "Memory usage decreased by -15.4%\n",
      "(6242440, 55)\n",
      "(1560611, 55)\n",
      "(6242440,)\n",
      "(1560611,)\n"
     ]
    }
   ],
   "source": [
    "# 80/20 time-based split to curb data leakage\n",
    "X_train, X_test, y_train, y_test = time_based_train_test_split(final_df_top_50, test_size=0.2)\n",
    "# final_df_top_50 = final_df_top_50.drop('date', axis=1)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(final_df_top_50.drop(['target'], axis=1), final_df_top_50['target'], test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
