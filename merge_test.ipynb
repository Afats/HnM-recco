{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<a id=\"Content\">HnM RecSys Notebook 9417</a>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-output": false,
    "tags": []
   },
   "source": [
    "## **<a id=\"Content\">Table of Contents</a>**\n",
    "* [**<span>1. Imports</span>**](#Imports)  \n",
    "* [**<span>2. Helper Functions/Decorators</span>**](#Helper-Functions)\n",
    "* [**<span>5. LightGBM Model</span>**](#LightGBM-Model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id  product_code          prod_name  product_type_no   \n",
      "0   108775015        108775          Strap top              253  \\\n",
      "1   108775044        108775          Strap top              253   \n",
      "2   108775051        108775      Strap top (1)              253   \n",
      "3   110065001        110065  OP T-shirt (Idro)              306   \n",
      "4   110065002        110065  OP T-shirt (Idro)              306   \n",
      "\n",
      "  product_type_name  product_group_name  graphical_appearance_no   \n",
      "0          Vest top  Garment Upper body                  1010016  \\\n",
      "1          Vest top  Garment Upper body                  1010016   \n",
      "2          Vest top  Garment Upper body                  1010017   \n",
      "3               Bra           Underwear                  1010016   \n",
      "4               Bra           Underwear                  1010016   \n",
      "\n",
      "  graphical_appearance_name  colour_group_code colour_group_name  ...   \n",
      "0                     Solid                  9             Black  ...  \\\n",
      "1                     Solid                 10             White  ...   \n",
      "2                    Stripe                 11         Off White  ...   \n",
      "3                     Solid                  9             Black  ...   \n",
      "4                     Solid                 10             White  ...   \n",
      "\n",
      "   department_name index_code        index_name index_group_no   \n",
      "0     Jersey Basic          A        Ladieswear              1  \\\n",
      "1     Jersey Basic          A        Ladieswear              1   \n",
      "2     Jersey Basic          A        Ladieswear              1   \n",
      "3   Clean Lingerie          B  Lingeries/Tights              1   \n",
      "4   Clean Lingerie          B  Lingeries/Tights              1   \n",
      "\n",
      "   index_group_name section_no            section_name garment_group_no   \n",
      "0        Ladieswear         16  Womens Everyday Basics             1002  \\\n",
      "1        Ladieswear         16  Womens Everyday Basics             1002   \n",
      "2        Ladieswear         16  Womens Everyday Basics             1002   \n",
      "3        Ladieswear         61         Womens Lingerie             1017   \n",
      "4        Ladieswear         61         Womens Lingerie             1017   \n",
      "\n",
      "   garment_group_name                                        detail_desc  \n",
      "0        Jersey Basic            Jersey top with narrow shoulder straps.  \n",
      "1        Jersey Basic            Jersey top with narrow shoulder straps.  \n",
      "2        Jersey Basic            Jersey top with narrow shoulder straps.  \n",
      "3   Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
      "4   Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "--\n",
      "                                         customer_id   FN  Active   \n",
      "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...  NaN     NaN  \\\n",
      "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...  NaN     NaN   \n",
      "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  NaN     NaN   \n",
      "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...  NaN     NaN   \n",
      "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...  1.0     1.0   \n",
      "\n",
      "  club_member_status fashion_news_frequency   age   \n",
      "0             ACTIVE                   NONE  49.0  \\\n",
      "1             ACTIVE                   NONE  25.0   \n",
      "2             ACTIVE                   NONE  24.0   \n",
      "3             ACTIVE                   NONE  54.0   \n",
      "4             ACTIVE              Regularly  52.0   \n",
      "\n",
      "                                         postal_code  \n",
      "0  52043ee2162cf5aa7ee79974281641c6f11a68d276429a...  \n",
      "1  2973abc54daa8a5f8ccfe9362140c63247c5eee03f1d93...  \n",
      "2  64f17e6a330a85798e4998f62d0930d14db8db1c054af6...  \n",
      "3  5d36574f52495e81f019b680c843c443bd343d5ca5b1c2...  \n",
      "4  25fa5ddee9aac01b35208d01736e57942317d756b32ddd...  \n",
      "--\n",
      "        t_dat                                        customer_id  article_id   \n",
      "0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   663713001  \\\n",
      "1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   541518023   \n",
      "2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   505221004   \n",
      "3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687003   \n",
      "4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...   685687004   \n",
      "\n",
      "      price  sales_channel_id  \n",
      "0  0.050831                 2  \n",
      "1  0.030492                 2  \n",
      "2  0.015237                 2  \n",
      "3  0.016932                 2  \n",
      "4  0.016932                 2  \n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "# import cudf # switch on P100 GPU for this to work in Kaggle\n",
    "# import cupy as cp\n",
    "\n",
    "# Importing data\n",
    "articles = pd.read_csv('articles.csv')\n",
    "print(articles.head())\n",
    "print(\"--\")\n",
    "customers = pd.read_csv('customers.csv')\n",
    "print(customers.head())\n",
    "print(\"--\")\n",
    "transactions = pd.read_csv(\"transactions_train.csv\")\n",
    "print(transactions.head())\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM imports\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open user_item_matrix_200\n",
    "with open('user_item_matrix_200.pkl', 'rb') as f:\n",
    "    user_item_matrix = pickle.load(f)\n",
    "\n",
    "# open customer and articels incides map\n",
    "with open('lightgbm/customer_id_indices_map.pkl', 'rb') as f:\n",
    "    customer_id_indices_map = pickle.load(f)\n",
    "\n",
    "with open('lightgbm/article_id_indices_map.pkl', 'rb') as f:\n",
    "    article_id_indices_map = pickle.load(f)\n",
    "\n",
    "# load df from pickle file for time-based split\n",
    "with open('lightgbm/df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "# load final_df from pickle file for clean processing\n",
    "with open('lightgbm/final_df_with_binary_targets.pkl', 'rb') as f:\n",
    "    final_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7803051, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126622, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\n"
     ]
    }
   ],
   "source": [
    "# get top 200 customers by number of transactions\n",
    "top_customers = transactions['customer_id'].value_counts().head(200).index.tolist()\n",
    "\n",
    "# print num of transactions for the 200th customer\n",
    "print(transactions['customer_id'].value_counts().sort_values(ascending=False).iloc[199])\n",
    "\n",
    "# only get articles that were purchased by top 200 customers at least once in articles df\n",
    "articles_top_200 = articles[articles['article_id'].isin(transactions[transactions['customer_id'].isin(top_customers)]['article_id'].unique())]\n",
    "\n",
    "# only get 200 customers in customers df\n",
    "customers_top_200 = customers[customers['customer_id'].isin(top_customers)]\n",
    "\n",
    "articles = articles_top_200.copy()\n",
    "customers = customers_top_200.copy()\n",
    "transactions = transactions[transactions['customer_id'].isin(top_customers)].copy()\n",
    "transactions = transactions.drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_final_df = customers.copy()\n",
    "transactions_final_df = transactions.copy()\n",
    "\n",
    "# Merge transactions with customers\n",
    "df = pd.merge(transactions_final_df, customers_final_df, on='customer_id', how='left')\n",
    "\n",
    "# Merge resulting dataframe with articles_final_df usually\n",
    "df = pd.merge(df, articles, on='article_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126709, 35)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001d44dbe7f6c4b35200abdb052c77a87596fe1bdcc37e011580a479e80aa94\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39mBuy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(customer)\n\u001b[1;32m---> 17\u001b[0m new_df \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39;49mappend([customers_1\u001b[39m.\u001b[39mloc[customers_1[\u001b[39m'\u001b[39m\u001b[39mcustomer_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mcustomer]]\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(articles_t))\u001b[39m.\u001b[39mreset_index(drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m new_df[\u001b[39m'\u001b[39m\u001b[39marticle_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(articles_t[\u001b[39m'\u001b[39m\u001b[39marticle_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m tran_temp \u001b[39m=\u001b[39m transactions_train_t\u001b[39m.\u001b[39mloc[transactions_train_t[\u001b[39m'\u001b[39m\u001b[39mcustomer_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39mcustomer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transactions_df = transactions.copy()\n",
    "\n",
    "transactions_df = transactions_df.drop_duplicates(subset=['customer_id','article_id'])\n",
    "transactions_df = transactions_df.reset_index(drop=True)\n",
    "\n",
    "customer_list = transactions_df.customer_id.value_counts()[:200].index.tolist()\n",
    "\n",
    "customers_1 = customers.loc[customers['customer_id'].isin(customer_list)]\n",
    "transactions_train_t = transactions_df.loc[transactions_df['customer_id'].isin(customer_list)]\n",
    "\n",
    "articles_t = articles.loc[articles['article_id'].isin(list(transactions_train_t['article_id']))]\n",
    "\n",
    "merge_df = pd.DataFrame(columns=['customer_id', 'Buy', 'article_id'])\n",
    "\n",
    "for customer in customers_1['customer_id']:\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['Buy'] = pd.Series(dtype='int64')\n",
    "    new_df = new_df.append([customers_1.loc[customers_1['customer_id'] == customer]] * len(articles_t)).reset_index(drop=True)\n",
    "    new_df['article_id'] = list(articles_t['article_id'])\n",
    "    tran_temp = transactions_train_t.loc[transactions_train_t['customer_id'] == customer]\n",
    "    for article in list(tran_temp['article_id']):\n",
    "        new_df.loc[(new_df['customer_id'] == customer) & (new_df['article_id'] == article), ['Buy']] = 1\n",
    "    merge_df = merge_df.append(new_df).reset_index(drop=True)\n",
    "\n",
    "merge_df['Buy'] = merge_df['Buy'].astype('int64')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
